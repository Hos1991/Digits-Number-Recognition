{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b6557f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03480733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Loading\n",
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "dir(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb90a004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5369c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of images: (1797, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "print('shape of images: {}'.format(digits.images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92c164e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (Examples) : (1797, 64)\n"
     ]
    }
   ],
   "source": [
    "print('X (Examples) : {}'.format(digits.data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c057e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y (Lables) : (1797,)\n"
     ]
    }
   ],
   "source": [
    "print('Y (Lables) : {}'.format(digits.target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8e3fdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set of output classes: {[0 1 2 3 4 5 6 7 8 9]}\n"
     ]
    }
   ],
   "source": [
    "print('set of output classes: {{{}}}'.format(digits.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "711c4499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(digits.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f298be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16da3e29070>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(16 - digits.images[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f5cd1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lable for above image: 0\n"
     ]
    }
   ],
   "source": [
    "print('Lable for above image: {}'.format(digits.target[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31fc8c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the labelled dataset into a training set and test set \n",
    "index_to_split = -1\n",
    "\n",
    "x_train = digits.data[:index_to_split] \n",
    "y_train = digits.target[:index_to_split]\n",
    "\n",
    "x_test = digits.data[index_to_split:]\n",
    "y_test = digits.target[index_to_split:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffe12840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w : [-2.28119225e-15  9.40249350e-02 -3.67939617e-03 -7.72167429e-03\n",
      "  7.49514697e-02  1.15243563e-02 -2.72158636e-02 -7.31904304e-03\n",
      "  1.00102690e+00 -2.84132215e-02  1.18887868e-01  6.59994113e-02\n",
      " -5.58787175e-02 -7.04137172e-02  9.65429164e-02  2.56033005e-01\n",
      " -7.29405068e-01  2.40605548e-02  7.76124220e-02 -2.29357716e-02\n",
      " -5.66039721e-02  5.81134072e-02 -4.91673806e-02 -2.62755693e-01\n",
      " -9.08254598e-01 -1.49425933e-01  5.59359249e-02  8.97465435e-02\n",
      "  8.39772547e-02  9.83482587e-02  1.86692450e-03 -2.97298764e+00\n",
      " -1.10924728e-14 -1.54851687e-01 -8.97570476e-03  1.39494684e-01\n",
      " -3.67398683e-02  5.46737441e-02 -9.53756017e-03  1.40487773e-15\n",
      "  1.00930061e-01  1.23968401e-01 -1.37042140e-02  5.34285543e-03\n",
      "  1.30949507e-01  5.51389202e-02  2.24650594e-02  7.76787978e-03\n",
      "  6.14807150e-01  2.67348801e-02  1.20233616e-03 -6.19644555e-02\n",
      " -2.06960828e-01 -3.39245068e-02  1.05783054e-01 -1.40682284e-01\n",
      " -1.01420937e+00 -1.13249749e-01  2.06527116e-02 -4.39417720e-02\n",
      "  1.85650152e-02 -6.65628180e-02  1.14557345e-02 -5.23335705e-02]\n"
     ]
    }
   ],
   "source": [
    "#Train model y = Xw\n",
    "x_train_inv = np.linalg.pinv(x_train)\n",
    "w = np.dot(x_train_inv, y_train)\n",
    "print('w : {}'.format(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93a1028b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat: [9.30939946], rounds to: 9\n",
      "Actual y label: [8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16da6ab74f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Test Model\n",
    "y_hat = x_test @ w\n",
    "print('y_hat: {}, rounds to: {}'.format(y_hat, int(np.round(y_hat)[0])))\n",
    "print('Actual y label: {}'.format(y_test))\n",
    "plt.figure()\n",
    "plt.imshow(16 - digits.images[-1], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78d80e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WITH SCIKIT-LEARN  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0451edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.Ridge(alpha=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9338e231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9722ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat: [8.7110152], rounds to: 9\n",
      "Actual y label: [8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16da6636ee0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_hat = reg.predict(x_test)\n",
    "print('y_hat: {}, rounds to: {}'.format(y_hat, int(np.round(y_hat)[0])))\n",
    "print('Actual y label: {}'.format(y_test))\n",
    "plt.figure()\n",
    "plt.imshow(16 - digits.images[-1], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8fe94ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ARDRegression',\n",
       " 'BayesianRidge',\n",
       " 'ElasticNet',\n",
       " 'ElasticNetCV',\n",
       " 'GammaRegressor',\n",
       " 'Hinge',\n",
       " 'Huber',\n",
       " 'HuberRegressor',\n",
       " 'Lars',\n",
       " 'LarsCV',\n",
       " 'Lasso',\n",
       " 'LassoCV',\n",
       " 'LassoLars',\n",
       " 'LassoLarsCV',\n",
       " 'LassoLarsIC',\n",
       " 'LinearRegression',\n",
       " 'Log',\n",
       " 'LogisticRegression',\n",
       " 'LogisticRegressionCV',\n",
       " 'ModifiedHuber',\n",
       " 'MultiTaskElasticNet',\n",
       " 'MultiTaskElasticNetCV',\n",
       " 'MultiTaskLasso',\n",
       " 'MultiTaskLassoCV',\n",
       " 'OrthogonalMatchingPursuit',\n",
       " 'OrthogonalMatchingPursuitCV',\n",
       " 'PassiveAggressiveClassifier',\n",
       " 'PassiveAggressiveRegressor',\n",
       " 'Perceptron',\n",
       " 'PoissonRegressor',\n",
       " 'RANSACRegressor',\n",
       " 'Ridge',\n",
       " 'RidgeCV',\n",
       " 'RidgeClassifier',\n",
       " 'RidgeClassifierCV',\n",
       " 'SGDClassifier',\n",
       " 'SGDRegressor',\n",
       " 'SquaredLoss',\n",
       " 'TheilSenRegressor',\n",
       " 'TweedieRegressor',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_base',\n",
       " '_bayes',\n",
       " '_cd_fast',\n",
       " '_coordinate_descent',\n",
       " '_glm',\n",
       " '_huber',\n",
       " '_least_angle',\n",
       " '_logistic',\n",
       " '_omp',\n",
       " '_passive_aggressive',\n",
       " '_perceptron',\n",
       " '_ransac',\n",
       " '_ridge',\n",
       " '_sag',\n",
       " '_sag_fast',\n",
       " '_sgd_fast',\n",
       " '_stochastic_gradient',\n",
       " '_theil_sen',\n",
       " 'enet_path',\n",
       " 'lars_path',\n",
       " 'lars_path_gram',\n",
       " 'lasso_path',\n",
       " 'orthogonal_mp',\n",
       " 'orthogonal_mp_gram',\n",
       " 'ridge_regression']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "816f739b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear least squares with l2 regularization.\n",
      "\n",
      "    Minimizes the objective function::\n",
      "\n",
      "    ||y - Xw||^2_2 + alpha * ||w||^2_2\n",
      "\n",
      "    This model solves a regression model where the loss function is\n",
      "    the linear least squares function and regularization is given by\n",
      "    the l2-norm. Also known as Ridge Regression or Tikhonov regularization.\n",
      "    This estimator has built-in support for multi-variate regression\n",
      "    (i.e., when y is a 2d-array of shape (n_samples, n_targets)).\n",
      "\n",
      "    Read more in the :ref:`User Guide <ridge_regression>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    alpha : {float, ndarray of shape (n_targets,)}, default=1.0\n",
      "        Regularization strength; must be a positive float. Regularization\n",
      "        improves the conditioning of the problem and reduces the variance of\n",
      "        the estimates. Larger values specify stronger regularization.\n",
      "        Alpha corresponds to ``1 / (2C)`` in other linear models such as\n",
      "        :class:`~sklearn.linear_model.LogisticRegression` or\n",
      "        :class:`~sklearn.svm.LinearSVC`. If an array is passed, penalties are\n",
      "        assumed to be specific to the targets. Hence they must correspond in\n",
      "        number.\n",
      "\n",
      "    fit_intercept : bool, default=True\n",
      "        Whether to fit the intercept for this model. If set\n",
      "        to false, no intercept will be used in calculations\n",
      "        (i.e. ``X`` and ``y`` are expected to be centered).\n",
      "\n",
      "    normalize : bool, default=False\n",
      "        This parameter is ignored when ``fit_intercept`` is set to False.\n",
      "        If True, the regressors X will be normalized before regression by\n",
      "        subtracting the mean and dividing by the l2-norm.\n",
      "        If you wish to standardize, please use\n",
      "        :class:`~sklearn.preprocessing.StandardScaler` before calling ``fit``\n",
      "        on an estimator with ``normalize=False``.\n",
      "\n",
      "    copy_X : bool, default=True\n",
      "        If True, X will be copied; else, it may be overwritten.\n",
      "\n",
      "    max_iter : int, default=None\n",
      "        Maximum number of iterations for conjugate gradient solver.\n",
      "        For 'sparse_cg' and 'lsqr' solvers, the default value is determined\n",
      "        by scipy.sparse.linalg. For 'sag' solver, the default value is 1000.\n",
      "\n",
      "    tol : float, default=1e-3\n",
      "        Precision of the solution.\n",
      "\n",
      "    solver : {'auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'},         default='auto'\n",
      "        Solver to use in the computational routines:\n",
      "\n",
      "        - 'auto' chooses the solver automatically based on the type of data.\n",
      "\n",
      "        - 'svd' uses a Singular Value Decomposition of X to compute the Ridge\n",
      "          coefficients. More stable for singular matrices than 'cholesky'.\n",
      "\n",
      "        - 'cholesky' uses the standard scipy.linalg.solve function to\n",
      "          obtain a closed-form solution.\n",
      "\n",
      "        - 'sparse_cg' uses the conjugate gradient solver as found in\n",
      "          scipy.sparse.linalg.cg. As an iterative algorithm, this solver is\n",
      "          more appropriate than 'cholesky' for large-scale data\n",
      "          (possibility to set `tol` and `max_iter`).\n",
      "\n",
      "        - 'lsqr' uses the dedicated regularized least-squares routine\n",
      "          scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative\n",
      "          procedure.\n",
      "\n",
      "        - 'sag' uses a Stochastic Average Gradient descent, and 'saga' uses\n",
      "          its improved, unbiased version named SAGA. Both methods also use an\n",
      "          iterative procedure, and are often faster than other solvers when\n",
      "          both n_samples and n_features are large. Note that 'sag' and\n",
      "          'saga' fast convergence is only guaranteed on features with\n",
      "          approximately the same scale. You can preprocess the data with a\n",
      "          scaler from sklearn.preprocessing.\n",
      "\n",
      "        All last five solvers support both dense and sparse data. However, only\n",
      "        'sag' and 'sparse_cg' supports sparse input when `fit_intercept` is\n",
      "        True.\n",
      "\n",
      "        .. versionadded:: 0.17\n",
      "           Stochastic Average Gradient descent solver.\n",
      "        .. versionadded:: 0.19\n",
      "           SAGA solver.\n",
      "\n",
      "    random_state : int, RandomState instance, default=None\n",
      "        Used when ``solver`` == 'sag' or 'saga' to shuffle the data.\n",
      "        See :term:`Glossary <random_state>` for details.\n",
      "\n",
      "        .. versionadded:: 0.17\n",
      "           `random_state` to support Stochastic Average Gradient.\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
      "        Weight vector(s).\n",
      "\n",
      "    intercept_ : float or ndarray of shape (n_targets,)\n",
      "        Independent term in decision function. Set to 0.0 if\n",
      "        ``fit_intercept = False``.\n",
      "\n",
      "    n_iter_ : None or ndarray of shape (n_targets,)\n",
      "        Actual number of iterations for each target. Available only for\n",
      "        sag and lsqr solvers. Other solvers will return None.\n",
      "\n",
      "        .. versionadded:: 0.17\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    RidgeClassifier : Ridge classifier.\n",
      "    RidgeCV : Ridge regression with built-in cross validation.\n",
      "    :class:`~sklearn.kernel_ridge.KernelRidge` : Kernel ridge regression\n",
      "        combines ridge regression with the kernel trick.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.linear_model import Ridge\n",
      "    >>> import numpy as np\n",
      "    >>> n_samples, n_features = 10, 5\n",
      "    >>> rng = np.random.RandomState(0)\n",
      "    >>> y = rng.randn(n_samples)\n",
      "    >>> X = rng.randn(n_samples, n_features)\n",
      "    >>> clf = Ridge(alpha=1.0)\n",
      "    >>> clf.fit(X, y)\n",
      "    Ridge()\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(reg.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72bc92d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: [-5.64361534e+13  3.09459962e-02 -2.07365975e-03 -2.76827104e-02\n",
      "  5.80919357e-02 -9.44738815e-03 -2.18717651e-02  9.50828917e-03\n",
      "  1.00479030e+00 -2.57607596e-02  1.12480243e-01  5.01294939e-02\n",
      " -6.85223556e-02 -6.95090984e-02  8.11943080e-02  2.49791650e-01\n",
      " -6.49404649e-01  2.88631635e-02  6.55043726e-02 -2.88956076e-02\n",
      " -7.02531171e-02  5.02353120e-02 -6.57798092e-02 -3.59653955e-01\n",
      " -9.70949885e-01 -1.85973841e-01  5.04475491e-02  7.95635385e-02\n",
      "  7.39014801e-02  9.12692465e-02 -1.69601276e-02 -1.79462024e+00\n",
      " -7.87448365e+13 -1.30470359e-01 -2.74166550e-02  1.44081727e-01\n",
      " -5.20538165e-02  3.88242999e-02 -1.81966307e-02 -4.98235749e+13\n",
      " -3.33325509e-02  1.11981425e-01 -2.58023607e-02 -7.63728045e-03\n",
      "  1.17385792e-01  5.28043352e-02  2.04959302e-02  1.89859258e-01\n",
      "  5.75520263e-01  1.63015871e-02  5.70168136e-04 -7.04057273e-02\n",
      " -2.03759031e-01 -3.74053660e-02  9.12234318e-02 -1.78842667e-01\n",
      " -1.23257462e+00 -8.37230510e-02 -6.50383138e-03 -6.32733630e-02\n",
      " -9.58151538e-03 -7.61418228e-02  3.54448605e-03 -4.97444397e-02]\n",
      "shape: (64,)\n"
     ]
    }
   ],
   "source": [
    "print('w: {}'.format(reg.coef_))\n",
    "print('shape: {}'.format(reg.coef_.shapepe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6973a45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
